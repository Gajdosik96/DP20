{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# fastai.torch_core.defaults.device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photo segmetantion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to annotationted mask images\n",
    "path_lbl = Path(\"data/unet_segmetation_task/#final/train_valid_masks\")\n",
    "# Path to original images\n",
    "path_img = Path(\"data/unet_segmetation_task/#final/train_valid\")\n",
    "# Path to test images\n",
    "path_tst = Path(\"data/unet_segmetation_task/adepts\")\n",
    "\n",
    "# create list of RGB values in order of idx value to replace with, i.e. 0: [0,0,0], 1: [128,0,0]\n",
    "rgb_list = [\n",
    "    [0,0,0],\n",
    "    [128,0,0]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From annotated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(tensor1d):\n",
    "    t, idx = np.unique(tensor1d.numpy(), return_inverse=True)\n",
    "    return torch.from_numpy(t), torch.from_numpy(idx), idx   \n",
    "\n",
    "def cut_from_folder(path_lbl, path_img, output_path):\n",
    "    if not output_path.exists():\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        to_separate = list(map(lambda x: path_img/f'{x.stem}.jpg', path_lbl.glob('*.png')))\n",
    "        for fn in to_separate:\n",
    "            shutil.copyfile(fn, output_path/f\"{fn.name.split('.')[0]}.png\")\n",
    "        \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call if you need separate annotated images from not annotated images to another folder\n",
    "# path_img = cut_from_folder(path_lbl, path_img, Path(\"data/UNET_segmentation_orig\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = get_image_files(path_img)\n",
    "fnames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get from test folder all images in Path posix\n",
    "tnames = get_image_files(path_tst)\n",
    "tnames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_names = get_image_files(path_lbl)\n",
    "lbl_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = np.loadtxt(path_lbl/'labels.txt', dtype=str,  ndmin=1); codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_y_fn = lambda x: path_lbl/f'{x.stem}.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_f = fnames[0]\n",
    "img = open_image(img_f)\n",
    "img.show(figsize=(5, 5))\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = open_mask(get_y_fn(img_f))\n",
    "mask.show(figsize=(10, 10), alpha=1)\n",
    "mask.size, mask.data\n",
    "\n",
    "# pozn.\n",
    "# src_size = np.array(mask.shape[1:])\n",
    "# src_size, mask.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values 't' in mask and their indecies\n",
    "t, idx_t, idx_n = unique(mask.data) \n",
    "t, idx_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (128, 128)\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegLabelListCustom(SegmentationLabelList):\n",
    "    def open(self, fn): \n",
    "        return open_mask(fn, div=True)\n",
    "    \n",
    "class SegItemListCustom(ImageList):\n",
    "    _label_cls = SegLabelListCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1\n",
    "src = (SegItemListCustom.from_folder(path_img)\n",
    "       # Load in x data from folder\n",
    "       .split_by_rand_pct(0.2, seed=random.randint(0, 100))\n",
    "       # Split data into training and validation set \n",
    "       .label_from_func(get_y_fn, classes=codes)\n",
    "#        Label data using the get_y_fn function\n",
    ")\n",
    "\n",
    "data = (src.transform(get_transforms(), size=size, tfm_y=True)\n",
    "        # Flip images horizontally \n",
    "        .databunch(bs=bs)\n",
    "        # Create a databunch\n",
    "        .normalize(imagenet_stats)\n",
    "        # Normalize for resnet\n",
    ")\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.show_batch(1, figsize=(10,10))\n",
    "data.show_batch(1, figsize=(10,10), ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name2id = {\n",
    "#     'none': 0,\n",
    "#     'picture': 1\n",
    "# }\n",
    "\n",
    "\n",
    "name2id = {v:k for k,v in enumerate(codes, 0)}\n",
    "print(name2id)\n",
    "\n",
    "# # Void - prazdno nezanotovane miesto (Pravdepodobne)\n",
    "\n",
    "def acc_picseg(input, target):\n",
    "    target = target.squeeze(1)\n",
    "    return (input.argmax(dim=1)==target).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = acc_picseg\n",
    "wd = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free = gpu_mem_get_free_no_cache()\n",
    "\n",
    "print(f\"using bs={bs}, have {free}MB of GPU RAM free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unet\n",
    "learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, slice(lr), pct_start=0.9) # train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1-128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1-128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=3, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(path_img / 'SK_MRS_1272_11_r.jpg'); img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = learn.predict(img)[0]; prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lrs = slice(lr/400,lr/20); lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20, lrs, pct_start=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2-128');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=1, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(path_img / 'SK_MRS_1272_11_r.jpg')\n",
    "prediction = learn.predict(img)[0]; prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, idx_t, idx_n = unique(prediction.data); t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, idx_t, idx_n  = np.unique(prediction.data.numpy(), return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of model 1 image\n",
    "\n",
    "import cv2\n",
    "\n",
    "new_img = cv2.imread('data/UNET_segmentation_orig/SK_MRS_1264_B1_r.png')\n",
    "new_img = cv2.resize(new_img, (128, 128))\n",
    "\n",
    "img = open_image('data/UNET_segmentation_orig/SK_MRS_1264_B1_r.png')\n",
    "prediction = learn.predict(img)[0]\n",
    "\n",
    "reshaped_mask = prediction.data.numpy().reshape(128, 128)\n",
    "\n",
    "# Add 1d mask to 3d mask\n",
    "mask_3d = np.dstack((reshaped_mask, reshaped_mask, reshaped_mask))\n",
    "# Convert numpy array to Image\n",
    "img_fastai = Image(pil2tensor(new_img * mask_3d, dtype=np.float32).div_(255)); img_fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = open_image('data/unet_segmetation_task/#2/train/SK_MRS_1309_B94_r.jpg'); new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of model 2 image\n",
    "\n",
    "import cv2\n",
    "\n",
    "new_img = cv2.imread('data/unet_segmetation_task/#2/train/SK_MRS_1309_B94_r.jpg')\n",
    "new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "new_img = cv2.resize(new_img, (128, 128))\n",
    "\n",
    "img = open_image('data/unet_segmetation_task/#2/train/SK_MRS_1309_B94_r.jpg')\n",
    "prediction = learn.predict(img)[0]\n",
    "\n",
    "reshaped_mask = prediction.data.numpy().reshape(128, 128)\n",
    "\n",
    "# Add 1d mask to 3d mask\n",
    "mask_3d = np.dstack((reshaped_mask, reshaped_mask, reshaped_mask))\n",
    "# Convert numpy array to Image\n",
    "img_fastai = Image(pil2tensor(new_img * mask_3d, dtype=np.float32).div_(255)); img_fastai\n",
    "\n",
    "# Resize Image\n",
    "# img_fastai.resize((1,1024,1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.destroy() # uncomment once 1.0.46 is out\n",
    "\n",
    "size = (512, 512)\n",
    "\n",
    "free = gpu_mem_get_free_no_cache()\n",
    "# the max size of bs depends on the available GPU RAM\n",
    "if free > 8200: bs=3\n",
    "else:           bs=1\n",
    "print(f\"using bs={bs}, have {free}MB of GPU RAM free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (src.transform(get_transforms(), size=size, tfm_y=True)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-2-128');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=5e-5\n",
    "learn.fit_one_cycle(10, slice(lr), pct_start=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1-big-512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1-big-512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST phase 1\n",
    "learn.show_results(rows=1, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(path_img / 'SK_MRS_1266_A12_r.jpg')\n",
    "prediction = learn.predict(img)[0]; prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe help to clear GPU memory 4me not working :(\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# print(gc.garbage)\n",
    "gpu_mem_get_free_no_cache()\n",
    "print(f\"using bs={bs}, have {free}MB of GPU RAM free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-5\n",
    "# lrs = slice(lr/100,lr/5); lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit_one_cycle(10, slice(lr), pct_start=0.8)\n",
    "learn.fit_one_cycle(20, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.show_results(rows=1, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2-big-512')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut image from original size input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('stage-4-big-1024')\n",
    "learn.load('stage-2-big-512');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get from test folder all images in Path posix\n",
    "tnames = get_image_files(path_tst)\n",
    "tnames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(tnames) - 1)\n",
    "img = open_image(tnames[idx])\n",
    "img.show(fig=(512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = learn.predict(img)[0]; prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction\n",
    "prediction.save(f\"data/unet_segmetation_task/#final/saved/{tnames[idx].stem}_m{tnames[idx].suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all adepts to segmetation model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get from test folder all images in Path posix\n",
    "tnames = get_image_files(path_tst)\n",
    "(tnames[:3], len(tnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name in tnames:\n",
    "    img = open_image(name)\n",
    "    prediction = learn.predict(img)[0]\n",
    "    prediction.save(f\"data/unet_segmetation_task/#final/saved/{name.stem}_m{name.suffix}\")\n",
    "    print(f\"data/unet_segmetation_task/#final/saved/{name.stem}_m{name.suffix}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
