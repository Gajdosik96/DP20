{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detekcia tv√°re\n",
    "---\n",
    "DP2020\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from pathlib import Path\n",
    "from helpers.pickleHelper import PickleHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU present test\n",
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()\n",
    "    print(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLib\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder with bw images not segmentated - only\n",
    "path_not_segmentated_bw_only = Path(\"data/final_output/bw_not_segmentated/imgs\")\n",
    "# Path to folder with bw images\n",
    "path_bw = Path(\"data/final_output/bw/imgs\")\n",
    "# Path to folder with colorized images\n",
    "path_rgb = Path(\"data/final_output/rgb/imgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bw_img = lambda x: path_bw / f\"{x.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for n, bw in enumerate(path_not_segmentated_bw_only.glob(\"*.jpg\")):\n",
    "    print(f\"Processed image n.{n}\")\n",
    "\n",
    "#     bw = get_bw_img(rgb)\n",
    "\n",
    "    image_np_rgb = np.array(Image.open(rgb))\n",
    "    image_np_bw = np.array(Image.open(bw))\n",
    "    if len(image_np_bw.shape) < 3 or image_np_bw.shape[2] == 1:\n",
    "        image_np_bw = np.dstack([image_np_bw, image_np_bw, image_np_bw])\n",
    "    \n",
    "#     print(f\"{rgb}: {image_np_rgb.shape}\")\n",
    "#     print(f\"{bw}: {image_np_bw.shape}\")\n",
    "\n",
    "    dets_rgb, scores_rgb, idx = detector.run(image_np_rgb, 1)\n",
    "    dets_bw, scores_bw, idx = detector.run(image_np_bw, 1)\n",
    "    data[bw.name] = {\"bw\": [dets_bw, scores_bw], \"rgb\": [dets_rgb, scores_rgb]}\n",
    "    \n",
    "PickleHelper.save(\"data/final_output/pkls/not_segmentated/FACE.pkl\", data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PickleHelper.load(\"data/final_output/pkls/not_segmentated/FACE.pkl\"); len(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetinaFace\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from insightface.RetinaFace.retinaface import RetinaFace\n",
    "from helpers.pickleHelper import PickleHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.01\n",
    "scales = [1024, 1980]\n",
    "\n",
    "count = 1\n",
    "\n",
    "gpuid = 0\n",
    "detector = RetinaFace('insightface/RetinaFace/models/retinaface/R50', 0, gpuid, 'net3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process analyse from folder of images and create .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder with bw images\n",
    "path_bw = Path(\"data/final_output/bw/imgs\")\n",
    "# Path to folder with colorized images\n",
    "path_rgb = Path(\"data/final_output/rgb/imgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(img, name, ext):\n",
    "    filename = f'./{name}{ext}'\n",
    "    print('writing', filename)\n",
    "    cv2.imwrite(filename, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(frame: np.ndarray):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(frame.astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(img, faces, landmarks, printout):\n",
    "    if faces is not None:\n",
    "        print(f'{printout} find', faces.shape[0], 'faces')\n",
    "        for i in range(faces.shape[0]):\n",
    "            print(f'{printout} score', faces[i][4])\n",
    "            box = faces[i].astype(np.int)\n",
    "            print(f'{printout} box', box)\n",
    "            #color = (255,0,0)\n",
    "            color = (0,0,255)\n",
    "            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "            if landmarks is not None:\n",
    "                landmark5 = landmarks[i].astype(np.int)\n",
    "                #print(landmark.shape)\n",
    "                for l in range(landmark5.shape[0]):\n",
    "                    color = (0,0,255)\n",
    "                    if l==0 or l==3:\n",
    "                        color = (0,255,0)\n",
    "                    cv2.circle(img, (landmark5[l][0], landmark5[l][1]), 1, color, 2)\n",
    "                \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bw_img = lambda x: path_bw / f\"{x.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result = False\n",
    "show_result = False\n",
    "\n",
    "data = {}\n",
    "for n, rgb in enumerate(path_rgb.glob(\"*.jpg\")):\n",
    "    print(f\"Processed image n.{n} - {rgb}\")\n",
    "    img_name = rgb.name\n",
    "    \n",
    "    bw_path = get_bw_img(rgb)\n",
    "    rgb_path = rgb\n",
    "\n",
    "    \n",
    "    bw = cv2.imread(bw_path.__str__())\n",
    "    rgb = cv2.imread(rgb_path.__str__())\n",
    "\n",
    "    if len(bw.shape) < 3 or bw.shape[2] == 1:\n",
    "        bw = np.dstack([bw, bw, bw])\n",
    "    \n",
    "    bw_im_shape = bw.shape\n",
    "    rgb_im_shape = rgb.shape\n",
    "    \n",
    "    target_size = scales[0]\n",
    "    max_size = scales[1]\n",
    "\n",
    "    bw_im_size_min = np.min(bw_im_shape[0:2])\n",
    "    bw_im_size_max = np.max(bw_im_shape[0:2])\n",
    "    \n",
    "    rgb_im_size_min = np.min(rgb_im_shape[0:2])\n",
    "    rgb_im_size_max = np.max(rgb_im_shape[0:2])\n",
    "    \n",
    "    bw_im_scale = float(target_size) / float(bw_im_size_min); bw_im_scale\n",
    "    rgb_im_scale = float(target_size) / float(rgb_im_size_min); rgb_im_scale\n",
    "\n",
    "    if np.round(bw_im_scale * bw_im_size_max) > max_size:\n",
    "        bw_im_scale = float(max_size) / float(bw_im_size_max); bw_im_scale\n",
    "    bw_scales = [bw_im_scale]\n",
    "    \n",
    "    if np.round(rgb_im_scale * rgb_im_size_max) > max_size:\n",
    "        rgb_im_scale = float(max_size) / float(rgb_im_size_max); rgb_im_scale\n",
    "    rgb_scales = [rgb_im_scale]\n",
    "    \n",
    "    \n",
    "    bw_faces, bw_landmarks = detector.detect(bw, thresh, scales=bw_scales, do_flip=False)\n",
    "    rgb_faces, rgb_landmarks = detector.detect(rgb, thresh, scales=rgb_scales, do_flip=False)\n",
    "\n",
    "    if save_result or show_result:\n",
    "        bw_res = print_result(bw, bw_faces, bw_landmarks, \"[BW]\")\n",
    "        rgb_res = print_result(rgb, rgb_faces, rgb_landmarks, \"[RGB]\")\n",
    "    \n",
    "    if save_result:\n",
    "        save_image(rgb_res, f\"{rgb_path.stem}_rgb_o\", rgb_path.suffix)\n",
    "        save_image(bw_res, f\"{bw_path.stem}_bw_o\", bw_path.suffix)\n",
    "        \n",
    "    if show_result:\n",
    "        show_image(rgb_res)\n",
    "        show_image(bw_res)\n",
    "        \n",
    "    data[img_name] = {\"rgb\": rgb_faces, \"bw\": bw_faces}\n",
    "    \n",
    "PickleHelper.save(\"data/final_output/pkls/segmentated_rgb_bw/RETINATNET_001.pkl\", data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from PIL import Image\n",
    "from nets import inception_resnet_v2\n",
    "from preprocessing import inception_preprocessing\n",
    "from helpers.pickleHelper import PickleHelper\n",
    "\n",
    "from datasets import dataset_utils\n",
    "from pathlib import Path\n",
    "\n",
    "# Main slim library\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder with bw images\n",
    "path_bw = Path(\"data/detection_task/bw_in_orig_size\")\n",
    "# Path to folder with colorized images\n",
    "path_rgb = Path(\"data/detection_task/rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bw_img = lambda x: path_bw / f\"{x.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz\"\n",
    "\n",
    "if not tf.gfile.Exists(checkpoints_dir):\n",
    "    tf.gfile.MakeDirs(checkpoints_dir)\n",
    "\n",
    "    dataset_utils.download_and_uncompress_tarball(url, checkpoints_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shw_image(frame: np.ndarray):\n",
    "        plt.figure()\n",
    "        plt.imshow(frame.astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(path_to_model, path_to_image):\n",
    "    image_size = inception_resnet_v2.inception_resnet_v2.default_image_size\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        frame = open(path_to_image, 'rb').read()\n",
    "        image = tf.image.decode_jpeg(frame, channels=3)\n",
    "        processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\n",
    "        processed_images  = tf.expand_dims(processed_image, 0)\n",
    "    \n",
    "        # Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "        with slim.arg_scope(inception.inception_resnet_v2_arg_scope()):\n",
    "            logits, _ = inception_resnet_v2.inception_resnet_v2(processed_images, num_classes=1001, is_training=False)\n",
    "        probabilities = tf.nn.softmax(logits)\n",
    "        \n",
    "        init_fn = slim.assign_from_checkpoint_fn(\n",
    "            os.path.join(checkpoints_dir, path_to_model),\n",
    "            slim.get_model_variables('InceptionResnetV2'))\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            init_fn(sess)\n",
    "            np_image, probabilities = sess.run([image, probabilities])\n",
    "            probabilities = probabilities[0, 0:]\n",
    "            sorted_inds = [i[0] for i in sorted(enumerate(-probabilities), key=lambda x:x[1])]\n",
    "        \n",
    "#         plt.figure()\n",
    "#         plt.imshow(np_image.astype(np.uint8))\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "        \n",
    "        return probabilities, sorted_inds\n",
    "        \n",
    "#         names = imagenet.create_readable_names_for_imagenet_labels()\n",
    "#         for i in range(5):\n",
    "#             index = sorted_inds[i]\n",
    "#             print('Probability %0.2f%% => [%s]' % (probabilities[index] * 100, names[index]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTCNN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import dlib\n",
    "from utils.pickleHelper import PickleHelper\n",
    "\n",
    "# Path to folder with bw images\n",
    "path_bw = Path(\"data/detection_task/bw_in_orig_size\")\n",
    "# Path to folder with colorized images\n",
    "path_rgb = Path(\"data/detection_task/rgb\")\n",
    "# Path to ground-truth .pkl file\n",
    "path_gt = PickleHelper.load(\"data/final_output/pkls/segmentated_rgb_bw/gt_250_faces.pkl\")\n",
    "\n",
    "get_bw_img = lambda x: path_bw / f\"{x}\"\n",
    "get_rgb_img = lambda x: path_rgb / f\"{x}\"\n",
    "\n",
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for n, img_name in enumerate(path_gt):\n",
    "#     img_name = \"Commonwealth Bank staff ca. 1925.jpg\"\n",
    "    print(f\"Processed image n.{n} - {img_name}\")\n",
    "\n",
    "    bw_path = get_bw_img(img_name)\n",
    "    rgb_path = get_rgb_img(img_name)\n",
    "\n",
    "    bw = cv2.cvtColor(cv2.imread(bw_path.__str__()), cv2.COLOR_BGR2RGB)\n",
    "    rgb = cv2.cvtColor(cv2.imread(rgb_path.__str__()), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if len(bw.shape) < 3 or bw.shape[2] == 1:\n",
    "        bw = np.dstack([bw, bw, bw])\n",
    "    \n",
    "#     shw_image(bw)\n",
    "#     shw_image(rgb)\n",
    "    \n",
    "    dets_bw = detector.detect_faces(bw)\n",
    "    dets_rgb = detector.detect_faces(rgb)\n",
    "    \n",
    "#     print(len(dets_bw))\n",
    "#     print(len(dets_rgb))\n",
    "    rgb_rects = list()\n",
    "    rgb_scores = list()\n",
    "    for d in dets_rgb:\n",
    "        # Bbox\n",
    "        rgb_rects.append(dlib.rectangle(left=d['box'][0], top=d['box'][1], right=d['box'][0] + d['box'][2], bottom=d['box'][1] + d['box'][3]))\n",
    "\n",
    "        # Score\n",
    "        rgb_scores.append(d['confidence']) \n",
    "    \n",
    "    \n",
    "    bw_rects = list()\n",
    "    bw_scores = list()\n",
    "    for d in dets_bw:\n",
    "        # Bbox\n",
    "        bw_rects.append(dlib.rectangle(left=d['box'][0], top=d['box'][1], right=d['box'][0] + d['box'][2], bottom=d['box'][1] + d['box'][3]))\n",
    "\n",
    "        # Score\n",
    "        bw_scores.append(d['confidence'])\n",
    "    \n",
    "    data[img_name] = {\"rgb\": [rgb_rects, rgb_scores], \"bw\": [bw_rects, bw_scores]}\n",
    "\n",
    "PickleHelper.save(\"data/final_output/pkls/segmentated_rgb_bw/MTCNN.pkl\", data)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
